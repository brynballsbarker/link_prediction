{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from load_data import load_data\n",
    "#from other_predictors import shortest_path, common_neighbors #, hitting_time\n",
    "#from predict_links import get_loc, delete_duplicates, predict\n",
    "#from effective_transition import brute_effective_transition, weighted_effective_transition\n",
    "#from spectral_embedding import spectral_embed\n",
    "from scipy.sparse import linalg as sla\n",
    "import scipy.sparse as ss\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import numpy.linalg as la\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from math import floor, ceil\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    myfile = open(filename, 'r')\n",
    "    lines = myfile.readlines()\n",
    "    lines = [line.split() for line in lines]\n",
    "    time = 3 if len(lines[0])==4 else 2\n",
    "    lines = [[int(line[0]),int(line[1]),int(line[time])] for line in lines]\n",
    "    lines.sort(key=lambda x: x[2])\n",
    "    n = len(lines)\n",
    "    chop = floor(3*n/4)\n",
    "    train = lines[:chop]\n",
    "    to_train = [(edge[0],edge[1]) for edge in train]\n",
    "    test = lines[chop:]\n",
    "    k = len(test)\n",
    "    to_predict = [(edge[0],edge[1]) for edge in test]\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(to_train)\n",
    "    G = max(nx.connected_component_subgraphs(G), key=len)\n",
    "    lines = [[int(line[0]),int(line[1]),int(line[time])] for line in lines]\n",
    "    lines.sort(key=lambda x: x[2])\n",
    "    n = len(lines)\n",
    "    chop = floor(3*n/4)\n",
    "    train = lines[:chop]\n",
    "    to_train = [(edge[0],edge[1]) for edge in train]\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(to_train)\n",
    "    G = max(nx.connected_component_subgraphs(G), key=len)\n",
    "    nodes = G.nodes()\n",
    "    test = lines[chop:]\n",
    "    to_predict = [(edge[0],edge[1]) for edge in test if edge[0] in nodes and edge[1] in nodes]\n",
    "\n",
    "    return G, to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_closest(points, k):\n",
    "    tree = KDTree(points)\n",
    "    dists,inds = tree.query(points, k+1)\n",
    "    n = points.shape[0]\n",
    "    a = np.arange(n).reshape((n,1))\n",
    "    mask = (inds != a)\n",
    "    ret_dists = np.empty((n,k))\n",
    "    ret_inds = np.empty((n,k))\n",
    "    for i in xrange(n):\n",
    "        mask = inds[i] != i\n",
    "        if sum(mask) > k:\n",
    "            mask = mask[:k]\n",
    "\n",
    "        ret_inds[i] = inds[i][mask]\n",
    "        ret_dists[i] = dists[i][mask]\n",
    "    return ret_dists, ret_inds\n",
    "\n",
    "def brute_closest_points(points, k=1):\n",
    "    n = len(points)\n",
    "    dists = pdist(points) #n-1, n-2, ..., n-3\n",
    "    inds = np.argsort(dists)[:k]\n",
    "\n",
    "\n",
    "    ind_arr = np.zeros((n*(n-1)/2, 2), dtype=int)\n",
    "    row = 0\n",
    "\n",
    "    for i in xrange(n):\n",
    "        for j in xrange(i+1,n):\n",
    "            ind_arr[row] = np.array([i,j])\n",
    "            row += 1\n",
    "\n",
    "\n",
    "    return ind_arr[inds], dists[inds]\n",
    "\n",
    "def remove_duplicate_points(points, dists):\n",
    "    points = np.sort(points)\n",
    "    max_ind = np.max(points, axis=None)\n",
    "    keys = max_ind * points[:,0] +  points[:,1]\n",
    "    keys, inds = np.unique(keys, return_index=True)\n",
    "    return points[inds], dists[inds]\n",
    "\n",
    "def metric(x,y):\n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "def closest_points(points, k=1, tol=1e-11):\n",
    "    \"\"\"\n",
    "    Given an array of points in Euclidean space, find the k pairs of points which are closest.\n",
    "    \"\"\"\n",
    "    n = points.shape[0]\n",
    "  #  print n, points.shape\n",
    "    if not n: return np.empty((0,2), dtype=int), np.array([])\n",
    "\n",
    "    l = int(ceil((4*k)/float(n)))\n",
    "    if n*n <= 4*k or n <= l:\n",
    "        return brute_closest_points(points,k)\n",
    "\n",
    "    dists, inds = all_closest(points,l)\n",
    "    npairs =  2*k\n",
    "\n",
    "    #find the indices corresponding to the closest 2*k distances, allowing repetition\n",
    "    #These aren't necessarily sorted, except for the very last distance\n",
    "    #Returns a tuple of row numbers (source points and column numbers (number of neighbor) \n",
    "    best_k_inds = np.unravel_index(np.argpartition(dists, npairs, axis=None)[:npairs], dists.shape)\n",
    "\n",
    "    #Use these indices to get the corresponding pairs of points\n",
    "    pairs = np.empty((npairs, 2), dtype=int)\n",
    "    pairs[:,0] = best_k_inds[0]\n",
    "    pairs[:,1] = inds[best_k_inds]\n",
    "\n",
    "    neighbor_counter = Counter(pairs[:,0])\n",
    "    \n",
    "    #the distances for these pairs\n",
    "    pdists = dists[best_k_inds]\n",
    "    pairs, pdists = remove_duplicate_points(pairs, pdists)\n",
    "    \n",
    "    #filter only the points that have all l nearest neighbors closer than the furthest pair so far\n",
    "    #we then recursively apply the algorithm to this set of points\n",
    "    #Figure out how many times each source index is repeated\n",
    "    mask = np.array([source for source in neighbor_counter if neighbor_counter[source] >= l], dtype=int)\n",
    "\n",
    "    S = points[mask]\n",
    "    s_closest, s_dists = closest_points(S, k, tol)\n",
    "    index_list = mask\n",
    "\n",
    "    firsts = index_list[s_closest[:,0]]\n",
    "    seconds = index_list[s_closest[:,1]]\n",
    "    all_points = np.zeros((len(firsts)+len(pdists),2), dtype = int)\n",
    "    all_points[:len(pdists)] = pairs\n",
    "    all_points[len(pdists):] = np.vstack([firsts, seconds]).T\n",
    "\n",
    "    all_dists = np.concatenate([pdists, s_dists])\n",
    "    all_points, all_dists = remove_duplicate_points(all_points, all_dists)\n",
    "    final_best_k = np.argsort(all_dists)[:k]\n",
    "    return all_points[final_best_k], all_dists[final_best_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortest_path(g, A):\n",
    "    \"\"\"\n",
    "    predicts links using shortest path method\n",
    "    \"\"\"\n",
    "    lengths = nx.shortest_path_length(g)\n",
    "    nodes = g.nodes()\n",
    "    num_nodes = len(nodes)\n",
    "\n",
    "    scores = np.zeros((num_nodes, num_nodes))\n",
    "    rev_dict = {nodes[i]: i for i in range(num_nodes)}\n",
    "    for n1 in lengths:\n",
    "            for n2 in lengths[n1]:\n",
    "                    scores[rev_dict[n1]][rev_dict[n2]] = lengths[n1][n2]\n",
    "    return -1*scores\n",
    "\n",
    "def common_neighbors(g, A):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    scores = np.dot(A,A)\n",
    "    return scores\n",
    "\n",
    "def preferential_attachment(g, A):\n",
    "    degrees = np.sum(A, axis=1)\n",
    "    scores = np.outer(degrees, degrees)\n",
    "    return scores\n",
    "\n",
    "def jacard(g, A):\n",
    "    num = np.dot(A,A)\n",
    "    # finish\n",
    "    return\n",
    "\n",
    "def katz(g, A):\n",
    "    return\n",
    "\n",
    "def delete_duplicates(pairs):\n",
    "    \"\"\"\n",
    "    deletes duplicate pairs from list pairs\n",
    "    \"\"\"\n",
    "    n = len(pairs)\n",
    "    copy = []\n",
    "    for pair in pairs:\n",
    "        copy.append(sorted(pair))\n",
    "\n",
    "    for i in range(1,n):\n",
    "        if copy.count(copy[n-i]) > 1:\n",
    "            del copy[n-i]\n",
    "    return copy\n",
    "\n",
    "def get_loc(pos, n):\n",
    "    \"\"\"\n",
    "    takes position in flattened array and gives location in non-flattened\n",
    "    \"\"\"\n",
    "    row = int(pos/n)\n",
    "    col = pos % n\n",
    "    return (row, col)\n",
    "\n",
    "def complement(first, second):\n",
    "    \"\"\"\n",
    "    returns the compliment of the first list in the second\n",
    "    \"\"\"\n",
    "    second = set(second)\n",
    "    return [item for item in first if item not in second]\n",
    "\n",
    "\n",
    "def backward_dict(pairs, nodes):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    n = len(pairs)\n",
    "    actual = [(nodes[pair[0]],nodes[pair[1]]) for pair in pairs]\n",
    "    return actual\n",
    "\n",
    "def predict(scores, nodes, A, k):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    n = len(nodes)\n",
    "    print('here')\n",
    "    pred = np.asarray(np.argsort(-1*(scores-10*A-10*np.eye(n)).reshape(n*n)))[0]\n",
    "    print(pred)\n",
    "    prediction = []\n",
    "    for p in pred[:2*k]:\n",
    "        prediction.append(get_loc(p,n))\n",
    "    prediction = delete_duplicates(prediction)[:k]\n",
    "    return backward_dict(prediction, nodes)\n",
    "\n",
    "def accuracy(prediction, to_predict):\n",
    "    return len(set(prediction)&set(to_predict))/len(to_predict)\n",
    "\n",
    "def partition(M, r, c):\n",
    "    \"\"\"\n",
    "    returns the r rows and c columns of matrix M\n",
    "    \"\"\"\n",
    "    part = []\n",
    "    for x in r:\n",
    "        for y in c:\n",
    "            part.append(M[x,y])\n",
    "    return np.array(part).reshape((len(r),len(c)))\n",
    "\n",
    "def scipy_eigsh(M, dim=1, tol=1e-8):\n",
    "    \"\"\"\n",
    "    returns the eigenvalue of largest magnitude corresponding to matrix M\n",
    "    \"\"\"\n",
    "    M = M.astype(np.float64)\n",
    "    sigma = sla.eigsh(M, k=dim, which='LM', tol=tol, return_eigenvectors=False)\n",
    "    return sigma[0]\n",
    "\n",
    "def brute_effective_transition(M,nodes,k):\n",
    "    \"\"\"\n",
    "    predicts k links for network with adjacency matrix M\n",
    "    \"\"\"\n",
    "    n = M.shape[0]\n",
    "    r = list(range(n))\n",
    "    eigval = scipy_eigsh(M)\n",
    "\n",
    "    R = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                first = csc_matrix(partition(M,[i,j],[i,j]))\n",
    "                comp = complement(r,[i,j])\n",
    "                second = csc_matrix(partition(M,[i,j],comp))\n",
    "                stuff = csc_matrix(partition(M, comp, comp)-eigval*np.eye(n-2))\n",
    "                third = sla.inv(stuff)\n",
    "                fourth = csc_matrix(partition(M, comp,[i,j]))\n",
    "                stuff = second.dot(third.dot(fourth))\n",
    "                R[i,j] = (first - stuff)[0,1]\n",
    "\n",
    "    pred = np.asarray(np.argsort(-1*(R - 10*M).reshape(n*n)))[0]\n",
    "\n",
    "    prediction = []\n",
    "    for p in pred[:2*k]:\n",
    "        prediction.append(get_loc(p,n))\n",
    "\n",
    "    almost = delete_duplicates(prediction)[:k]\n",
    "    return backward_dict(almost, nodes)\n",
    "\n",
    "def weighted_effective_transition(A,k):\n",
    "    \"\"\"\n",
    "    predicts k links for network with adjacency matrix M\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    degrees = np.sum(A, axis=1)\n",
    "    M = A/d\n",
    "    r = list(range(n))\n",
    "    eigval = scipy_eigsh(M)\n",
    "\n",
    "    R = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                first = partition(M,[i,j],[i,j])\n",
    "                comp = complement(r,[i,j])\n",
    "                second = partition(M,[i,j],comp)\n",
    "                temp = partition(M, comp, comp)\n",
    "                third = np.linalg.inv(partition(M, comp, comp)-eigval*np.identity(n-2))\n",
    "                fourth = partition(M, comp,[i,j])\n",
    "                R[i,j] = (first - np.dot(second,np.dot(third,fourth)))[0,1]\n",
    "\n",
    "    pred = np.asarray(np.argsort(-1*(R - 10*M).reshape(n*n)))[0]\n",
    "\n",
    "    prediction = []\n",
    "    for p in pred[:2*k]:\n",
    "        prediction.append(get_loc(p,n))\n",
    "\n",
    "    almost = delete_duplicates(prediction)[:k]\n",
    "    return backward_dict(almost, nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0., -1., -1., ..., -2., -2., -2.],\n",
       "       [-1., -0., -1., ..., -2., -2., -1.],\n",
       "       [-1., -1., -0., ..., -2., -2., -2.],\n",
       "       ...,\n",
       "       [-2., -2., -2., ..., -0., -3., -3.],\n",
       "       [-2., -2., -2., ..., -3., -0., -3.],\n",
       "       [-2., -1., -2., ..., -3., -3., -0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path(G,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods = []\n",
    "times = []\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = '/home/byu.local/brynbb/myacmeshare/link_prediction/data/haggledata.txt'\n",
    "G, to_predict = load_data(filename)\n",
    "nodes = G.nodes()\n",
    "A = nx.adjacency_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    }
   ],
   "source": [
    "print(len(to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 178)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0. -1. -1. ... -2. -2. -2.]\n",
      " [-1. -0. -1. ... -2. -2. -1.]\n",
      " [-1. -1. -0. ... -2. -2. -2.]\n",
      " ...\n",
      " [-2. -2. -2. ... -0. -3. -3.]\n",
      " [-2. -2. -2. ... -3. -0. -3.]\n",
      " [-2. -1. -2. ... -3. -3. -0.]]\n",
      "here\n",
      "[28337 12680 12681 ...  7028  7130  5176]\n",
      "[(36, 235), (43, 83), (44, 83), (45, 83), (198, 200)]\n",
      "done with shortest\n",
      "here\n",
      "[ 2327  2506  9666 ...  9777 29958   884]\n",
      "done with common neighbors\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spectral_embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fd6e7a731820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectral_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Spectral Embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spectral_embed' is not defined"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "start = time.time()\n",
    "scores = shortest_path(G,A)\n",
    "print(scores)\n",
    "prediction = predict(scores, nodes, A, k)\n",
    "print(prediction)\n",
    "acc = accuracy(prediction, to_predict)\n",
    "methods.append('Shortest Path')\n",
    "times.append(time.time()-start)\n",
    "accs.append(acc)\n",
    "print('done with shortest')\n",
    "\n",
    "\"\"\"start = time.time()\n",
    "prediction = brute_effective_transition(A,nodes, k)\n",
    "acc = accuracy(prediction, to_predict)\n",
    "methods.append('Effective Transition')\n",
    "times.append(time.time()-start)\n",
    "accs.append(acc)\n",
    "print('done with shortest')\n",
    "\n",
    "start = time.time()\n",
    "prediction = brute_effective_transition(A, nodes,k)\n",
    "acc = accuracy(prediction, to_predict)\n",
    "methods.append('Weighted Effective Transition')\n",
    "times.append(time.time()-start)\n",
    "accs.append(acc)\n",
    "print('done with shortest')\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "scores = common_neighbors(G, A)\n",
    "prediction = predict(scores, nodes, A, k)\n",
    "acc = accuracy(prediction, to_predict)\n",
    "methods.append('Common Neighbors')\n",
    "times.append(time.time()-start)\n",
    "accs.append(acc)\n",
    "print('done with common neighbors')\n",
    "\n",
    "start = time.time()\n",
    "prediction = spectral_embed(G, k, dim=4)\n",
    "acc = accuracy(prediction, to_predict)\n",
    "methods.append('Spectral Embedding')\n",
    "times.append(time.time()-start)\n",
    "accs.append(acc)\n",
    "print('done with spectral embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03240466117858887, 0.0032432079315185547]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
